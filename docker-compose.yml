version: '3.8'

services:
  inference-service:
    build: .
    image: mlops-cats-dogs:latest
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
    restart: always

  frontend-service:
    image: python:3.9-slim
    working_dir: /app
    volumes:
      - ./frontend:/app
    ports:
      - "5500:5500"
    command: python -m http.server 5500

  mlflow-service:
    image: mlops-cats-dogs:latest
    ports:
      - "5001:5001"
    volumes:
      - ./mlruns:/app/mlruns
    command: mlflow ui --host 0.0.0.0 --port 5001
